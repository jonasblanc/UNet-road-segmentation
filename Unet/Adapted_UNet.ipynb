{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2993aa5b",
   "metadata": {},
   "source": [
    "## Adapted Unet\n",
    "In the this notebook is the pipeline to train and create submission with an adapted UNet. It uses padding to predict an image of the same size than the input. We made the claim than since it's only based on convolution, the size doesn't matter much. So we predict the submission images in the same way.\n",
    "\n",
    "Training: (3x400x400) => (400x400)  \n",
    "Submission: (3x608x608) => (608x608)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14eac046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from Adapted_UNet import *\n",
    "from images_helpers import *\n",
    "from unet_helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcb2cd6",
   "metadata": {},
   "source": [
    "### Load data, create training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c14ccb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 images loaded\n",
      "900 images loaded\n",
      "100 images loaded\n",
      "100 images loaded\n"
     ]
    }
   ],
   "source": [
    "# Training dataset\n",
    "train_imgs,_ = load_images(UNET_PREFIX + AUGMENTED_IMAGE_TRAIN_DIR)\n",
    "train_gt_imgs,_ = load_images(UNET_PREFIX + AUGMENTED_GT_TRAIN_DIR)\n",
    "\n",
    "train_img_tensor = images_to_tensor(train_imgs)\n",
    "train_gt_tensor = gts_to_tensor(train_gt_imgs)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(train_img_tensor, train_gt_tensor)\n",
    "\n",
    "# Test dataset\n",
    "test_imgs,_ = load_images(UNET_PREFIX + AUGMENTED_IMAGE_TEST_DIR)\n",
    "test_gt_imgs,_ = load_images(UNET_PREFIX + AUGMENTED_GT_TEST_DIR)\n",
    "\n",
    "test_img_tensor = images_to_tensor(test_imgs)\n",
    "test_gt_tensor = gts_to_tensor(test_gt_imgs)\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(test_img_tensor, test_gt_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2e78a2",
   "metadata": {},
   "source": [
    "### Train the unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2c40f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING PARAMETERS\n",
    "INIT_LR = 0.001\n",
    "NUM_EPOCHS = 200\n",
    "BATCH_SIZE = 4\n",
    "PROBA_DROPOUT = 0\n",
    "PROBA_DROPOUT_MIDDLE = 0.3\n",
    "lossFunc = BCEWithLogitsLoss()\n",
    "#lossFunc = sigmoid_f1_loss\n",
    "\n",
    "LOAD_MODEL = False\n",
    "LOAD_MODEL_NAME = UNET_PREFIX + MODEL_DIR + \"unet_epoch_28\"\n",
    "LOAD_OPT_NAME = UNET_PREFIX + MODEL_DIR + \"unet_epoch_28_opt\"\n",
    "\n",
    "MODEL_BATCH_NAME = UNET_PREFIX + MODEL_DIR + \"unet_batch_\"\n",
    "MODEL_EPOCH_NAME = UNET_PREFIX + MODEL_DIR + \"unet_epoch_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96c0a870",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "unet = UNet(PROBA_DROPOUT, PROBA_DROPOUT_MIDDLE).to(DEVICE)\n",
    "opt = Adam(unet.parameters(), lr=INIT_LR)\n",
    "if LOAD_MODEL:\n",
    "    unet.load_state_dict(torch.load(LOAD_MODEL_NAME))\n",
    "    opt.load_state_dict(torch.load(LOAD_OPT_NAME))\n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bd93265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fd2afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet, opt, losses, test_losses = train_model(unet, opt, NUM_EPOCHS, train_loader,test_dataset, lossFunc,\\\n",
    "                                             num_testing=80, num_test_per_epoch=7, num_save_per_epoch=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1699739f",
   "metadata": {},
   "source": [
    "### Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca341b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67c03d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBMISSION_PREDICTION_DIR = UNET_PREFIX + \"predictions_submission/\"\n",
    "TEST_SET_DIR = UNET_PREFIX + \"data/test_set_images/\"\n",
    "\n",
    "test_files = os.listdir(TEST_SET_DIR)\n",
    "imgs = [load_image(TEST_SET_DIR + f + \"/\" + f +\".png\") for f in test_files]\n",
    "imgs = np.array([np.moveaxis(img, -1, 0) for img in imgs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f33fdf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = UNet(PROBA_DROPOUT, PROBA_DROPOUT_MIDDLE).to(DEVICE)\n",
    "model.load_state_dict(torch.load(UNET_PREFIX + MODEL_DIR + \"unet_epoch_28\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0df32c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 0\n",
      "Saved 2\n",
      "Saved 4\n",
      "Saved 6\n",
      "Saved 8\n",
      "Saved 10\n",
      "Saved 12\n",
      "Saved 14\n",
      "Saved 16\n",
      "Saved 18\n",
      "Saved 20\n",
      "Saved 22\n",
      "Saved 24\n",
      "Saved 26\n",
      "Saved 28\n",
      "Saved 30\n",
      "Saved 32\n",
      "Saved 34\n",
      "Saved 36\n",
      "Saved 38\n",
      "Saved 40\n",
      "Saved 42\n",
      "Saved 44\n",
      "Saved 46\n",
      "Saved 48\n",
      "../predictions_submission/test_1.png\n",
      "../predictions_submission/test_10.png\n",
      "../predictions_submission/test_11.png\n",
      "../predictions_submission/test_12.png\n",
      "../predictions_submission/test_13.png\n",
      "../predictions_submission/test_14.png\n",
      "../predictions_submission/test_15.png\n",
      "../predictions_submission/test_16.png\n",
      "../predictions_submission/test_17.png\n",
      "../predictions_submission/test_18.png\n",
      "../predictions_submission/test_19.png\n",
      "../predictions_submission/test_2.png\n",
      "../predictions_submission/test_20.png\n",
      "../predictions_submission/test_21.png\n",
      "../predictions_submission/test_22.png\n",
      "../predictions_submission/test_23.png\n",
      "../predictions_submission/test_24.png\n",
      "../predictions_submission/test_25.png\n",
      "../predictions_submission/test_26.png\n",
      "../predictions_submission/test_27.png\n",
      "../predictions_submission/test_28.png\n",
      "../predictions_submission/test_29.png\n",
      "../predictions_submission/test_3.png\n",
      "../predictions_submission/test_30.png\n",
      "../predictions_submission/test_31.png\n",
      "../predictions_submission/test_32.png\n",
      "../predictions_submission/test_33.png\n",
      "../predictions_submission/test_34.png\n",
      "../predictions_submission/test_35.png\n",
      "../predictions_submission/test_36.png\n",
      "../predictions_submission/test_37.png\n",
      "../predictions_submission/test_38.png\n",
      "../predictions_submission/test_39.png\n",
      "../predictions_submission/test_4.png\n",
      "../predictions_submission/test_40.png\n",
      "../predictions_submission/test_41.png\n",
      "../predictions_submission/test_42.png\n",
      "../predictions_submission/test_43.png\n",
      "../predictions_submission/test_44.png\n",
      "../predictions_submission/test_45.png\n",
      "../predictions_submission/test_46.png\n",
      "../predictions_submission/test_47.png\n",
      "../predictions_submission/test_48.png\n",
      "../predictions_submission/test_49.png\n",
      "../predictions_submission/test_5.png\n",
      "../predictions_submission/test_50.png\n",
      "../predictions_submission/test_6.png\n",
      "../predictions_submission/test_7.png\n",
      "../predictions_submission/test_8.png\n",
      "../predictions_submission/test_9.png\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(t):\n",
    "    return np.exp(-np.logaddexp(0, -t))\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    idx = 0;\n",
    "    \n",
    "    files_pred = []\n",
    "    for i in range(len(imgs)):\n",
    "        if i % 2 ==0:\n",
    "            xs = imgs[i:i+2]\n",
    "            x = torch.tensor(xs).to(DEVICE)\n",
    "            y_pred = model(x)\n",
    "            y_pred=y_pred.cpu()\n",
    "            for j in range(y_pred.shape[0]):\n",
    "                y_pred_ = sigmoid(y_pred[j,0].detach().numpy()) \n",
    "                y_pred_ = np.where(y_pred_ > 0.5, 1, 0)            \n",
    "\n",
    "                img_pred = from_mask_to_img(y_pred_)\n",
    "                pred_name = SUBMISSION_PREDICTION_DIR + test_files[idx]+\".png\"\n",
    "                img_pred.save(pred_name)\n",
    "                idx += 1\n",
    "                files_pred.append(pred_name)\n",
    "            print(f\"Saved {i}\")\n",
    "\n",
    "\n",
    "    masks_to_submission(\"submissionUnet\", *files_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620bcf3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
